{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from utils import generate_training_data_set, generate_testing_data_set, TinyImageNet\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pickle\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "#generate_training_data_set(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_triplet, label_triplet = pickle.load(open(\"./pickle/train_1.p\",'rb'))\n",
    "train = TinyImageNet(img_triplet, label_triplet, train=True, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=2,\n",
    "                                           shuffle=False, sampler=SubsetRandomSampler(range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([2, 3, 224, 224]) tensor([139,  63])\n",
      "1 torch.Size([2, 3, 224, 224]) tensor([166, 132])\n"
     ]
    }
   ],
   "source": [
    "for idx, (data, target) in enumerate(train_loader):\n",
    "    print(idx, data[0].shape, target[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = generate_testing_data_set()\n",
    "test = TinyImageNet(img, label, train=False, transform=transform_train)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=2,\n",
    "                                           shuffle=False, sampler=SubsetRandomSampler(range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torchvision.models.resnet.ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2])\n",
    "net.load_state_dict(torch.load(\"../data/model/resnet18-5c106cde.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch: [1/30] | Loss:[4.910797208547592]\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "import utils\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "epoch = 0\n",
    "use_cuda = torch.cuda.is_available()\n",
    "net =  torchvision.models.resnet.ResNet(torchvision.models.resnet.Bottleneck, [3, 4, 23, 3])\n",
    "net.load_state_dict(torch.load(\"../data/model/resnet101-5d3b4d8f.pth\"))\n",
    "net.fc = nn.Linear(in_features=net.fc.in_features, out_features=4096)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-06)\n",
    "training_loss_seq = []\n",
    "testing_accuracy_seq = []\n",
    "testing_loss_seq = []\n",
    "testing_best_accuracy = 0\n",
    "if not os.path.isfile(\"./pickle/train_{}.p\".format(epoch)):\n",
    "    img_triplet, label_triplet = utils.generate_training_data_set(save=True,epoch_idx=epoch)\n",
    "else:\n",
    "    img_triplet, label_triplet = pickle.load(open(\"./pickle/train_{}.p\".format(epoch), 'rb'))\n",
    "train_dataset = utils.TinyImageNet(img_triplet, label_triplet, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, num_workers=4,\n",
    "                                           shuffle=False, sampler=SubsetRandomSampler(range(50)))\n",
    "net.train()\n",
    "loss_epoch = []\n",
    "for _, (images, _) in enumerate(train_loader):\n",
    "    if use_cuda:\n",
    "        q, p, n = images[0].cuda(), images[1].cuda(), images[2].cuda()\n",
    "    else:\n",
    "        q, p, n = images[0], images[1], images[2]\n",
    "    optimizer.zero_grad()\n",
    "    q, p, n = Variable(q), Variable(p), Variable(n)\n",
    "    f_q, f_p, f_n = net(q), net(p), net(n)\n",
    "    loss = criterion(f_q, f_p, f_n)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if torch.__version__ == '0.4.1':\n",
    "        loss_epoch.append(loss.item())\n",
    "    else:\n",
    "        loss_epoch.append(loss.data[0])\n",
    "loss = np.mean(loss_epoch)\n",
    "print(\"=> Epoch: [{}/{}] | Loss:[{}]\".format(epoch + 1, 30, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0770889520645142,\n",
       " 0.7435991168022156,\n",
       " 1.519863486289978,\n",
       " 4.663661956787109,\n",
       " 3.9388535022735596,\n",
       " 4.634669780731201,\n",
       " 2.446793556213379,\n",
       " 4.2676496505737305,\n",
       " 13.153558731079102,\n",
       " 12.662233352661133]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 2, 5, 1, 6])\n",
      "tensor([4, 3, 0, 9, 7])\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, num_workers=4,\n",
    "                                           shuffle=False, sampler=SubsetRandomSampler([0,503,1003,1503,2003,2503,3003,3503,4003,4503]))\n",
    "for _, (imgs, labels) in enumerate(train_loader):\n",
    "    print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 2\n",
    "img, label = utils.generate_testing_data_set()\n",
    "test_dataset = utils.TinyImageNet(img, label, train=False, transform=transform_train)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=2,\n",
    "                                          sampler=SubsetRandomSampler(range(8)))\n",
    "f_img_train = []\n",
    "label_train = []\n",
    "for _, (imgs, labels) in enumerate(train_loader):\n",
    "    if use_cuda:\n",
    "        imgs, lables = imgs.cuda(), labels.cuda()\n",
    "    f_img_train.append(net(imgs[0]))\n",
    "    label_train.append(labels[0])\n",
    "f_img_train = torch.cat(f_img_train, dim=0)\n",
    "label_train = torch.cat(label_train, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([161, 140, 107,  69])\n",
      "tensor([ 69, 147, 139,  73])\n"
     ]
    }
   ],
   "source": [
    "for _, (imgs, labels) in enumerate(test_loader):\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_img_test = []\n",
    "label_test = []\n",
    "for idx, (imgs, labels) in enumerate(test_loader):\n",
    "    if use_cuda:\n",
    "        imgs, lables = imgs.cuda(), labels.cuda()\n",
    "    f_img_test.append(net(imgs))\n",
    "    label_test.append(labels)\n",
    "f_img_test = torch.cat(f_img_test, dim=0)\n",
    "label_test = torch.cat(label_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 9]) tensor(139)\n",
      "tensor([1, 3]) tensor(140)\n",
      "tensor([1, 3]) tensor(161)\n",
      "tensor([6, 9]) tensor(147)\n",
      "tensor([1, 9]) tensor(73)\n",
      "tensor([1, 3]) tensor(69)\n",
      "tensor([6, 1]) tensor(107)\n",
      "tensor([6, 9]) tensor(69)\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = []\n",
    "for fig_embedding_current, lable_current in zip(f_img_test, label_test):\n",
    "    fig_embedding_current = fig_embedding_current.reshape(1, 4096)\n",
    "    fig_embedding_current = fig_embedding_current.expand(f_img_train.shape[0], 4096)\n",
    "    pdist = nn.PairwiseDistance(p=2)\n",
    "    distance = pdist(fig_embedding_current, f_img_train)\n",
    "    predicted = label_train[distance.topk(topk)[1]]\n",
    "    print(predicted, lable_current)\n",
    "    test_accuracy.append(float(torch.sum(torch.eq(predicted, lable_current))) / topk)\n",
    "test_accuracy_epoch = np.mean(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import utils\n",
    "class Args:\n",
    "    def __init__(self, num_epochs=2, batch_size=100, train_all=True, resume='./checkpoint.pth.tar', test_only=True):\n",
    "        self.num_epochs=2\n",
    "        self.batch_size=10\n",
    "        self.train_all=True\n",
    "        self.resume='./checkpoint.pth.tar'\n",
    "        self.test_only=False\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation...\n",
      "Loading Data...\n",
      "Model setting...\n",
      "Resume from the checkpoint...\n",
      "=> no checkpoint found at './checkpoint.pth.tar'\n",
      "=> Training based on the resnet-101 from scratch...\n",
      "Model Training...\n"
     ]
    }
   ],
   "source": [
    "log_level = logging.INFO\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(log_level)\n",
    "handler = logging.FileHandler(\"hw5.log\")\n",
    "handler.setLevel(log_level)\n",
    "formatter = logging.Formatter('%(asctime)s - [%(levelname)s] - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.info(\"torch version: {}\".format(torch.__version__))\n",
    "\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = args.batch_size\n",
    "topk = 30\n",
    "pdist = nn.PairwiseDistance(p=2)\n",
    "# Data Preparation\n",
    "\n",
    "# note that mean and std is calculated channel-wise\n",
    "# reference: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/10\n",
    "print(\"Data Preparation...\")\n",
    "logger.info(\"Data Preparation...\")\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "logger.info(\"Loading Data...\")\n",
    "img, label = utils.generate_testing_data_set()\n",
    "test_dataset = utils.TinyImageNet(img, label, train=False, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "if args.test_only:\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=2,\n",
    "                                              sampler=SubsetRandomSampler(range(8)))\n",
    "print(\"Model setting...\")\n",
    "logger.info(\"Model setting...\")\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "start_epoch = 0\n",
    "net = torchvision.models.resnet.ResNet(torchvision.models.resnet.Bottleneck, [3, 4, 23, 3])\n",
    "net.load_state_dict(torch.load(\"../data/model/resnet101-5d3b4d8f.pth\"))\n",
    "\n",
    "# Do not change the layers that are pre-trained with the only exception\n",
    "# on the last full-connected layer.\n",
    "if not args.train_all:\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "# change the last fc layer for cifar100\n",
    "net.fc = nn.Linear(in_features=net.fc.in_features, out_features=4096)\n",
    "\n",
    "#optimizer = optim.Adam(net.parameters())\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-06)\n",
    "training_loss_seq = []\n",
    "training_accuracy_seq = []\n",
    "testing_accuracy_seq = []\n",
    "testing_best_accuracy = 0\n",
    "\n",
    "if args.resume:\n",
    "    print(\"Resume from the checkpoint...\")\n",
    "    logger.info(\"Resume from the checkpoint...\")\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        net.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        training_loss_seq = checkpoint['training_loss_seq']\n",
    "        training_accuracy_seq = checkpoint['training_accuracy_seq']\n",
    "        testing_accuracy_seq = checkpoint['testing_accuracy_seq']\n",
    "        testing_best_accuracy = checkpoint['testing_best_accuracy']\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, (checkpoint['epoch'] + 1)))\n",
    "        logger.info(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                    .format(args.resume, (checkpoint['epoch'] + 1)))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "        logger.info(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "        print(\"=> Training based on the resnet-101 from scratch...\")\n",
    "        logger.info(\"=> Training based on the resnet-101 from scratch...\")\n",
    "else:\n",
    "    print(\"=> Training based on the resnet-18 from scratch...\")\n",
    "    logger.info(\"=> Training based on the resnet-18 from scratch...\")\n",
    "\n",
    "\n",
    "print(\"Model Training...\")\n",
    "logger.info(\"Model Training...\")\n",
    "\n",
    "# use up-to-date learning rate; for resume purpose\n",
    "for param_group in optimizer.param_groups:\n",
    "    current_learningRate = param_group['lr']\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    print(torch.cuda.device_count())\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "def train(epoch,topk=30):\n",
    "    if args.test_only:\n",
    "        topk = 3\n",
    "        img_triplet, label_triplet = pickle.load(open(\"./pickle/train_1.p\", 'rb'))\n",
    "        train_dataset = utils.TinyImageNet(img_triplet, label_triplet, transform=transform_train)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, num_workers=2,\n",
    "                                           shuffle=False, sampler=SubsetRandomSampler([0,503,1003,1503,2003,2503,3003,3503,4003,4503]))\n",
    "    else:\n",
    "        if not os.path.isfile(\"./pickle/train_{}.p\".format(epoch)):\n",
    "            img_triplet, label_triplet = utils.generate_training_data_set(save=True, epoch_idx=epoch)\n",
    "        else:\n",
    "            img_triplet, label_triplet = pickle.load(open(\"./pickle/train_{}.p\".format(epoch), 'rb'))\n",
    "        train_dataset = utils.TinyImageNet(img_triplet, label_triplet, train=True, transform=transform_train)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    global current_learningRate\n",
    "    net.train()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        current_learningRate /= 2\n",
    "        logger.info(\"=> Learning rate is updated!\")\n",
    "        utils.update_learning_rate(optimizer, current_learningRate)\n",
    "\n",
    "    f_img_train = []\n",
    "    label_train = []\n",
    "    for _, (images, lables) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            q, p, n, q_label = images[0].cuda(), images[1].cuda(), images[2].cuda(), lables[0].cuda()\n",
    "        else:\n",
    "            q, p, n, q_label = images[0], images[1], images[2], lables[0]\n",
    "        optimizer.zero_grad()\n",
    "        q, p, n = Variable(q), Variable(p), Variable(n)\n",
    "        f_q, f_p, f_n = net(q), net(p), net(n)\n",
    "        loss = criterion(f_q, f_p, f_n)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        f_img_train.append(f_q)\n",
    "        label_train.append(q_label)\n",
    "\n",
    "    if torch.__version__ == '0.4.1':\n",
    "        loss_epoch = loss.item()\n",
    "    else:\n",
    "        loss_epoch = loss.data[0]\n",
    "\n",
    "    f_img_train = torch.cat(f_img_train, dim=0)\n",
    "    label_train = torch.cat(label_train, dim=0)\n",
    "\n",
    "    train_accuracy = []\n",
    "    # calculate train_acc so use train_loader as the test_loader\n",
    "    for f_img_test_current, label_test_current in zip(f_img_train, label_train):\n",
    "        f_img_test_current = f_img_test_current.reshape(1, 4096)\n",
    "        f_img_test_current = f_img_test_current.expand(f_img_train.shape[0], 4096)\n",
    "        distance = pdist(f_img_test_current, f_img_train)\n",
    "        predicted = label_train[distance.topk(topk)[1]]\n",
    "        train_accuracy.append(float(torch.sum(torch.eq(predicted, label_test_current))) / topk)\n",
    "    train_accuracy_epoch = np.mean(train_accuracy)\n",
    "\n",
    "    print(\"=> Epoch: [{}/{}] | Loss:[{}] | Training Accuracy: [{}]\".format(epoch + 1, args.num_epochs, loss_epoch, train_accuracy_epoch))\n",
    "    logger.info(\"=> Epoch: [{}/{}] | Loss:[{}] | Training Accuracy: [{}]\".format(epoch + 1, args.num_epochs, loss_epoch, train_accuracy_epoch))\n",
    "    return loss_epoch, train_accuracy_epoch, f_img_train, label_train\n",
    "\n",
    "\n",
    "def test(epoch, f_img_train, label_train, topk=30):\n",
    "    net.eval()\n",
    "    if args.test_only:\n",
    "        topk = 3\n",
    "    #f_img_train = []\n",
    "    #label_train = []\n",
    "    # for _, (imgs_train, labels_train) in enumerate(train_loader):\n",
    "    #     if use_cuda:\n",
    "    #         imgs_train, labels_train = imgs_train.cuda(), labels_train.cuda()\n",
    "    #     f_img_train.append(net(imgs_train[0]))\n",
    "    #     label_train.append(labels_train[0])\n",
    "    # f_img_train = torch.cat(f_img_train, dim=0)\n",
    "    # label_train = torch.cat(label_train, dim=0)\n",
    "\n",
    "    f_img_test = []\n",
    "    label_test = []\n",
    "    for _, (imgs_test, labels_test) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            imgs_test, labels_test = imgs_test.cuda(), labels_test.cuda()\n",
    "        #f_img_test, label_test = Variable(f_img_test), Variable(label_test)\n",
    "        f_img_test.append(net(imgs_test))\n",
    "        label_test.append(labels_test)\n",
    "\n",
    "    f_img_test = torch.cat(f_img_test, dim=0)\n",
    "    label_test = torch.cat(label_test, dim=0)\n",
    "\n",
    "    test_accuracy = []\n",
    "    for f_img_test_current, label_test_current in zip(f_img_test, label_test):\n",
    "        f_img_test_current = f_img_test_current.reshape(1, 4096)\n",
    "        f_img_test_current = f_img_test_current.expand(f_img_train.shape[0], 4096)\n",
    "        distance = pdist(f_img_test_current, f_img_train)\n",
    "        predicted = label_train[distance.topk(topk)[1]]\n",
    "        test_accuracy.append(float(torch.sum(torch.eq(predicted, label_test_current))) / topk)\n",
    "    test_accuracy_epoch = np.mean(test_accuracy)\n",
    "\n",
    "    print(\"=> Epoch: [{}/{}] | Testing Accuracy: [{}]\".format(\n",
    "        epoch + 1, args.num_epochs, test_accuracy_epoch))\n",
    "    logger.info(\"=> Epoch: [{}/{}] | Testing Accuracy: [{}]\".format(\n",
    "        epoch + 1, args.num_epochs, test_accuracy_epoch))\n",
    "\n",
    "    return test_accuracy_epoch\n",
    "\n",
    "\n",
    "# for epoch in range(start_epoch, args.num_epochs):\n",
    "#     train_loss, train_accuracy, f_img_train, label_train = train(epoch)\n",
    "#     test_accuracy = test(epoch, f_img_train, label_train)\n",
    "\n",
    "#     training_loss_seq.append(train_loss)\n",
    "#     training_accuracy_seq.append(train_accuracy)\n",
    "#     testing_accuracy_seq.append(test_accuracy)\n",
    "\n",
    "#     is_best = testing_accuracy_seq[-1] > testing_best_accuracy\n",
    "#     testing_best_accuracy = max(testing_best_accuracy, testing_accuracy_seq[-1])\n",
    "\n",
    "#     state = {\n",
    "#         \"epoch\": epoch,\n",
    "#         \"state_dict\": net.state_dict(),  # if use_cuda else net.module.state_dict()\n",
    "#         \"optimizer\": optimizer.state_dict(),\n",
    "#         \"training_loss_seq\": training_loss_seq,\n",
    "#         \"training_accuracy_seq\": training_accuracy_seq,\n",
    "#         \"testing_accuracy_seq\": testing_accuracy_seq,\n",
    "#         \"testing_best_accuracy\": testing_best_accuracy\n",
    "#     }\n",
    "#     utils.save_checkpoint(state, is_best, filename='checkpoint.pth.tar', extra=\"hw5_\")\n",
    "#     if is_best:\n",
    "#         logger.info(\"=> Best parameters are updated\")\n",
    "\n",
    "\n",
    "# logger.info(\"=> Trained on [{}] epoch, with test accuracy [{}].\\n \\\n",
    "#  During the training stages, historical best test accuracy is \\\n",
    "#  [{}]\".format(args.num_epochs, testing_accuracy_seq[-1], testing_best_accuracy))\n",
    "# print(\"=> Trained on [{}] epoch, with test accuracy [{}].\\n \\\n",
    "#  During the training stages, historical best test accuracy is \\\n",
    "#  [{}]\".format(args.num_epochs, testing_accuracy_seq[-1], testing_best_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch: [1/2] | Loss:[0.31766223907470703] | Training Accuracy: [0.0]\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_accuracy, f_img_train, label_train = train(epoch)\n",
    "test_accuracy = test(epoch, f_img_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Epoch: [1/2] | Testing Accuracy: [0.0]\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = test(epoch, f_img_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, f_img_train, label_train):\n",
    "    net.eval()\n",
    "    if args.test_only:\n",
    "        topk = 3\n",
    "    #f_img_train = []\n",
    "    #label_train = []\n",
    "    # for _, (imgs_train, labels_train) in enumerate(train_loader):\n",
    "    #     if use_cuda:\n",
    "    #         imgs_train, labels_train = imgs_train.cuda(), labels_train.cuda()\n",
    "    #     f_img_train.append(net(imgs_train[0]))\n",
    "    #     label_train.append(labels_train[0])\n",
    "    # f_img_train = torch.cat(f_img_train, dim=0)\n",
    "    # label_train = torch.cat(label_train, dim=0)\n",
    "\n",
    "    f_img_test = []\n",
    "    label_test = []\n",
    "    for _, (imgs_test, labels_test) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            imgs_test, labels_test = imgs_test.cuda(), labels_test.cuda()\n",
    "        #f_img_test, label_test = Variable(f_img_test), Variable(label_test)\n",
    "        f_img_test.append(net(imgs_test))\n",
    "        label_test.append(labels_test)\n",
    "\n",
    "    f_img_test = torch.cat(f_img_test, dim=0)\n",
    "    label_test = torch.cat(label_test, dim=0)\n",
    "\n",
    "    test_accuracy = []\n",
    "    for f_img_test_current, label_test_current in zip(f_img_test, label_test):\n",
    "        f_img_test_current = f_img_test_current.reshape(1, 4096)\n",
    "        f_img_test_current = f_img_test_current.expand(f_img_train.shape[0], 4096)\n",
    "        distance = pdist(f_img_test_current, f_img_train)\n",
    "        predicted = label_train[distance.topk(topk)[1]]\n",
    "        test_accuracy.append(float(torch.sum(torch.eq(predicted, label_test_current))) / topk)\n",
    "    test_accuracy_epoch = np.mean(test_accuracy)\n",
    "\n",
    "    print(\"=> Epoch: [{}/{}] | Testing Accuracy: [{}]\".format(\n",
    "        epoch + 1, args.num_epochs, test_accuracy_epoch))\n",
    "    logger.info(\"=> Epoch: [{}/{}] | Testing Accuracy: [{}]\".format(\n",
    "        epoch + 1, args.num_epochs, test_accuracy_epoch))\n",
    "\n",
    "    return test_accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../data/cifar-100-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='../data', train=True, download=True, transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /Users/ym/.torch/models/resnet18-5c106cde.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /Users/ym/.torch/models/resnet101-5d3b4d8f.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "resnet18 = models.resnet101(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
