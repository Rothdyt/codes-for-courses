{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import utils\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.num_epochs=2\n",
    "        self.batch_size=10\n",
    "        self.train_all=True\n",
    "        self.net = \"resnet18\"\n",
    "        self.resume='./hw5_checkpoint.pth.tar'\n",
    "        self.test_only=True\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation...\n",
      "Loading Data...\n",
      "Model setting...\n",
      "using resnet18\n",
      "Resume from the checkpoint...\n",
      "=> loading checkpoint './hw5_checkpoint.pth.tar'\n",
      "=> loaded checkpoint './hw5_checkpoint.pth.tar' (epoch 2)\n",
      "Model Training...\n",
      "=> Trained on [2] epoch, with test accuracy [0.0].\n",
      "  During the training stages, historical best test accuracy is  [0]\n"
     ]
    }
   ],
   "source": [
    "log_level = logging.INFO\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(log_level)\n",
    "handler = logging.FileHandler(\"hw5.log\")\n",
    "handler.setLevel(log_level)\n",
    "formatter = logging.Formatter('%(asctime)s - [%(levelname)s] - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.info(\"torch version: {}\".format(torch.__version__))\n",
    "\n",
    "\n",
    "# Hyper Parameters\n",
    "batch_size = args.batch_size\n",
    "pdist = nn.PairwiseDistance(p=2)\n",
    "# Data Preparation\n",
    "\n",
    "# note that mean and std is calculated channel-wise\n",
    "# reference: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/10\n",
    "print(\"Data Preparation...\")\n",
    "logger.info(\"Data Preparation...\")\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Loading Data...\")\n",
    "logger.info(\"Loading Data...\")\n",
    "img, label = utils.generate_testing_data_set()\n",
    "test_dataset = utils.TinyImageNet(img, label, train=False, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "if args.test_only:\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=False, num_workers=2,\n",
    "                                              sampler=SubsetRandomSampler(range(8)))\n",
    "print(\"Model setting...\")\n",
    "logger.info(\"Model setting...\")\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "start_epoch = 0\n",
    "if args.net == \"resnet18\":\n",
    "    print(\"using resnet18\")\n",
    "    net = torchvision.models.resnet.ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2])\n",
    "    if not os.path.isfile(args.resume):\n",
    "        net.load_state_dict(torch.load(\"../data/model/resnet18-5c106cde.pth\"))\n",
    "else:\n",
    "    print(\"using resnet101\")\n",
    "    net = torchvision.models.resnet.ResNet(torchvision.models.resnet.Bottleneck, [3, 4, 23, 3])\n",
    "    if not os.path.isfile(args.resume):\n",
    "        net.load_state_dict(torch.load(\"../data/model/resnet101-5d3b4d8f.pth\"))\n",
    "# Do not change the layers that are pre-trained with the only exception\n",
    "# on the last full-connected layer.\n",
    "if not args.train_all:\n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False\n",
    "# change the last fc layer for cifar100\n",
    "net.fc = nn.Linear(in_features=net.fc.in_features, out_features=4096)\n",
    "\n",
    "if use_cuda:\n",
    "    net.cuda()\n",
    "    net = torch.nn.DataParallel(net, device_ids=range(torch.cuda.device_count()))\n",
    "    print(torch.cuda.device_count())\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "criterion = nn.TripletMarginLoss(margin=1.0, p=2, eps=1e-06)\n",
    "training_loss_seq = []\n",
    "training_accuracy_seq = []\n",
    "testing_accuracy_seq = []\n",
    "testing_best_accuracy = 0\n",
    "\n",
    "if args.resume:\n",
    "    print(\"Resume from the checkpoint...\")\n",
    "    logger.info(\"Resume from the checkpoint...\")\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        net.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        training_loss_seq = checkpoint['training_loss_seq']\n",
    "        #training_accuracy_seq = checkpoint['training_accuracy_seq']\n",
    "        testing_accuracy_seq = checkpoint['testing_accuracy_seq']\n",
    "        testing_best_accuracy = checkpoint['testing_best_accuracy']\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, (checkpoint['epoch'] + 1)))\n",
    "        logger.info(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                    .format(args.resume, (checkpoint['epoch'] + 1)))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "        logger.info(\"=> no checkpoint found at '{}'\".format(args.resume))\n",
    "        print(\"=> Training based on the resnet-101 from scratch...\")\n",
    "        logger.info(\"=> Training based on the resnet-101 from scratch...\")\n",
    "else:\n",
    "    print(\"=> Training based on the resnet-18 from scratch...\")\n",
    "    logger.info(\"=> Training based on the resnet-18 from scratch...\")\n",
    "\n",
    "\n",
    "print(\"Model Training...\")\n",
    "logger.info(\"Model Training...\")\n",
    "\n",
    "# use up-to-date learning rate; for resume purpose\n",
    "for param_group in optimizer.param_groups:\n",
    "    current_learningRate = param_group['lr']\n",
    "\n",
    "\n",
    "def train(epoch, k_closet=30):\n",
    "    if args.test_only:\n",
    "        k_closet = 3\n",
    "        img_triplet, label_triplet = pickle.load(open(\"./pickle/train_1.p\", 'rb'))\n",
    "        train_dataset = utils.TinyImageNet(img_triplet, label_triplet, transform=transform_train)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, num_workers=2,\n",
    "                                                   shuffle=False, sampler=SubsetRandomSampler([0, 503, 1003, 1503, 2003, 2503, 3003, 3503, 4003, 4503]))\n",
    "    else:\n",
    "        if not os.path.isfile(\"./pickle/train_{}.p\".format(epoch)):\n",
    "            img_triplet, label_triplet = utils.generate_training_data_set(save=True, epoch_idx=epoch)\n",
    "        else:\n",
    "            img_triplet, label_triplet = pickle.load(open(\"./pickle/train_{}.p\".format(epoch), 'rb'))\n",
    "        train_dataset = utils.TinyImageNet(img_triplet, label_triplet, train=True, transform=transform_train)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "\n",
    "    global current_learningRate\n",
    "    net.train()\n",
    "    if (epoch+1) % 5 == 0:\n",
    "        current_learningRate /= 2\n",
    "        logger.info(\"=> Learning rate is updated!\")\n",
    "        utils.update_learning_rate(optimizer, current_learningRate)\n",
    "\n",
    "    f_img_train = []\n",
    "    label_train = []\n",
    "    #train_bacth_accuracy = []\n",
    "    loss_epoch = 0\n",
    "    for _, (images, lables) in enumerate(train_loader):\n",
    "        #start = time.time()\n",
    "        if use_cuda:\n",
    "            q, p, n, q_label = images[0].cuda(), images[1].cuda(), images[2].cuda(), lables[0].cuda()\n",
    "        else:\n",
    "            q, p, n, q_label = images[0], images[1], images[2], lables[0]\n",
    "        optimizer.zero_grad()\n",
    "        q, p, n = Variable(q), Variable(p), Variable(n)\n",
    "        f_q, f_p, f_n = net(q), net(p), net(n)\n",
    "        loss = criterion(f_q, f_p, f_n)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if torch.__version__ == '0.4.1':\n",
    "            loss_epoch += loss.item()\n",
    "            # print(loss_epoch)\n",
    "        else:\n",
    "            loss_epoch += loss.data[0]\n",
    "            # print(loss_epoch)\n",
    "        f_img_train.append(f_q)\n",
    "        label_train.append(q_label)\n",
    "        #end = time.time()\n",
    "        #print(\"time for one batch {} s\".format(end-start))\n",
    "        # calculate train_acc so use train_loader as the test_loader\n",
    "    #     train_accuracy = []\n",
    "    #     for f_img_test_current, label_test_current in zip(f_q, q_label):\n",
    "    #         f_img_test_current = f_img_test_current.reshape(1, 4096)\n",
    "    #         f_img_test_current = f_img_test_current.expand(f_q.shape[0], 4096)\n",
    "    #         distance = pdist(f_img_test_current, f_q)\n",
    "    #         predicted = q_label[distance.topk(k_closet, largest=False)[1]]\n",
    "    #         train_accuracy.append(float(torch.sum(torch.eq(predicted, label_test_current))) / k_closet)\n",
    "    #     train_bacth_accuracy.append(np.mean(train_accuracy))\n",
    "    # train_accuracy_epoch = np.mean(train_bacth_accuracy)\n",
    "\n",
    "    f_img_train = torch.cat(f_img_train, dim=0)\n",
    "    label_train = torch.cat(label_train, dim=0)\n",
    "\n",
    "    # train_accuracy = []\n",
    "    # # calculate train_acc so use train_loader as the test_loader\n",
    "    # for f_img_test_current, label_test_current in zip(f_img_train, label_train):\n",
    "    #     f_img_test_current = f_img_test_current.reshape(1, 4096)\n",
    "    #     f_img_test_current = f_img_test_current.expand(f_img_train.shape[0], 4096)\n",
    "    #     distance = pdist(f_img_test_current, f_img_train)\n",
    "    #     predicted = label_train[distance.topk(k_closet)[1]]\n",
    "    #     train_accuracy.append(float(torch.sum(torch.eq(predicted, label_test_current))) / k_closet)\n",
    "    # train_accuracy_epoch = np.mean(train_accuracy)\n",
    "\n",
    "    # print(\"=> Epoch: [{}/{}] | Loss:[{}] | Training Accuracy: [{}]\".format(epoch + 1, args.num_epochs, loss_epoch, train_accuracy_epoch))\n",
    "    # logger.info(\"=> Epoch: [{}/{}] | Loss:[{}] | Training Accuracy: [{}]\".format(epoch + 1, args.num_epochs, loss_epoch, train_accuracy_epoch))\n",
    "    # return loss_epoch, train_accuracy_epoch, f_img_train, label_train\n",
    "    print(\"=> Epoch: [{}/{}] | Loss:[{}]\".format(epoch + 1, args.num_epochs, loss_epoch))\n",
    "    logger.info(\"=> Epoch: [{}/{}] | Loss:[{}]\".format(epoch + 1, args.num_epochs, loss_epoch))\n",
    "    return loss_epoch, f_img_train, label_train\n",
    "\n",
    "\n",
    "def test(epoch, f_img_train, label_train, k_closet=30):\n",
    "    net.eval()\n",
    "    if args.test_only:\n",
    "        k_closet = 3\n",
    "    # f_img_train = []\n",
    "    # label_train = []\n",
    "    # for _, (imgs_train, labels_train) in enumerate(train_loader):\n",
    "    #     if use_cuda:\n",
    "    #         imgs_train, labels_train = imgs_train.cuda(), labels_train.cuda()\n",
    "    #     f_img_train.append(net(imgs_train[0]))\n",
    "    #     label_train.append(labels_train[0])\n",
    "    # f_img_train = torch.cat(f_img_train, dim=0)\n",
    "    # label_train = torch.cat(label_train, dim=0)\n",
    "\n",
    "    # f_img_test = []\n",
    "    # label_test = []\n",
    "    # for _, (imgs_test, labels_test) in enumerate(test_loader):\n",
    "    #     if use_cuda:\n",
    "    #         imgs_test, labels_test = imgs_test.cuda(), labels_test.cuda()\n",
    "    #     #f_img_test, label_test = Variable(f_img_test), Variable(label_test)\n",
    "    #     f_img_test.append(net(imgs_test))\n",
    "    #     label_test.append(labels_test)\n",
    "\n",
    "    # f_img_test = torch.cat(f_img_test, dim=0)\n",
    "    # label_test = torch.cat(label_test, dim=0)\n",
    "\n",
    "    # test_accuracy = []\n",
    "    # for f_img_test_current, label_test_current in zip(f_img_test, label_test):\n",
    "    #     f_img_test_current = f_img_test_current.reshape(1, 4096)\n",
    "    #     f_img_test_current = f_img_test_current.expand(f_img_train.shape[0], 4096)\n",
    "    #     distance = pdist(f_img_test_current, f_img_train)\n",
    "    #     predicted = label_train[distance.topk(k_closet)[1]]\n",
    "    #     test_accuracy.append(float(torch.sum(torch.eq(predicted, label_test_current))) / k_closet)\n",
    "    # test_accuracy_epoch = np.mean(test_accuracy)\n",
    "\n",
    "    test_accuracy = []\n",
    "    for _, (imgs_test, labels_test) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            imgs_test, labels_test = imgs_test.cuda(), labels_test.cuda()\n",
    "        imgs_test = Variable(imgs_test)\n",
    "        with torch.no_grad():\n",
    "            f_img_test = net(imgs_test)\n",
    "        for f_img_test_current, label_test_current in zip(f_img_test, labels_test):\n",
    "            f_img_test_current = f_img_test_current.reshape(1, 4096)\n",
    "            f_img_test_current = f_img_test_current.expand(f_img_train.shape[0], 4096)\n",
    "            distance = pdist(f_img_test_current, f_img_train)\n",
    "            predicted = label_train[distance.topk(k_closet)[1]]\n",
    "            test_accuracy.append(float(torch.sum(torch.eq(predicted, label_test_current))) / k_closet)\n",
    "    test_accuracy_epoch = np.mean(test_accuracy)\n",
    "\n",
    "    print(\"=> Epoch: [{}/{}] | Testing Accuracy: [{}]\".format(\n",
    "        epoch + 1, args.num_epochs, test_accuracy_epoch))\n",
    "    logger.info(\"=> Epoch: [{}/{}] | Testing Accuracy: [{}]\".format(\n",
    "        epoch + 1, args.num_epochs, test_accuracy_epoch))\n",
    "\n",
    "    return test_accuracy_epoch\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, args.num_epochs):\n",
    "    #train_loss, train_accuracy, f_img_train, label_train = train(epoch)\n",
    "    train_loss, f_img_train, label_train = train(epoch)\n",
    "    f_img_train = f_img_train.detach()\n",
    "    # if (epoch+1) % 2 == 0:\n",
    "    test_accuracy = test(epoch, f_img_train, label_train)\n",
    "    training_loss_seq.append(train_loss)\n",
    "    # training_accuracy_seq.append(train_accuracy)\n",
    "    testing_accuracy_seq.append(test_accuracy)\n",
    "\n",
    "    is_best = testing_accuracy_seq[-1] > testing_best_accuracy\n",
    "    testing_best_accuracy = max(testing_best_accuracy, testing_accuracy_seq[-1])\n",
    "\n",
    "    state = {\n",
    "        \"epoch\": epoch,\n",
    "        \"state_dict\": net.state_dict(),  # if use_cuda else net.module.state_dict()\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"training_loss_seq\": training_loss_seq,\n",
    "        # \"training_accuracy_seq\": training_accuracy_seq,\n",
    "        \"testing_accuracy_seq\": testing_accuracy_seq,\n",
    "        \"testing_best_accuracy\": testing_best_accuracy\n",
    "    }\n",
    "    utils.save_checkpoint(state, is_best, filename='checkpoint.pth.tar', extra=\"hw5_\")\n",
    "    if is_best:\n",
    "        logger.info(\"=> Best parameters are updated\")\n",
    "\n",
    "\n",
    "logger.info(\"=> Trained on [{}] epoch, with test accuracy [{}].\\n \\\n",
    " During the training stages, historical best test accuracy is \\\n",
    " [{}]\".format(args.num_epochs, testing_accuracy_seq[-1], testing_best_accuracy))\n",
    "print(\"=> Trained on [{}] epoch, with test accuracy [{}].\\n \\\n",
    " During the training stages, historical best test accuracy is \\\n",
    " [{}]\".format(args.num_epochs, testing_accuracy_seq[-1], testing_best_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_triplet, label_triplet = pickle.load(open(\"./pickle/train_{}.p\".format(2), 'rb'))\n",
    "# train_dataset = utils.TinyImageNet(img_triplet, label_triplet, train=True, transform=transform_train)\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "#                                                 batch_size=batch_size, shuffle=True, num_workers=32)\n",
    "# f_img_train = []\n",
    "# label_train = []\n",
    "# for idx, (images, lables) in enumerate(train_loader):\n",
    "#     if idx % 100 == 0:\n",
    "#         print(idx)\n",
    "#     if use_cuda:\n",
    "#             q = images[0].cuda()\n",
    "#     else:\n",
    "#         q, q_label = images[0], lables[0]\n",
    "#     with torch.no_grad():\n",
    "#         q = Variable(q)\n",
    "#         f_q = net(q)\n",
    "#     f_img_train.append(f_q)\n",
    "#     label_train.append(q_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import utils\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.num_epochs=2\n",
    "        self.batch_size=10\n",
    "        self.train_all=True\n",
    "        self.net = \"resnet18\"\n",
    "        self.resume='./hw5_checkpoint.pth.tar'\n",
    "        self.test_only=True\n",
    "args = Args()\n",
    "\n",
    "net = torchvision.models.resnet.ResNet(torchvision.models.resnet.BasicBlock, [2, 2, 2, 2])\n",
    "net.fc = nn.Linear(in_features=net.fc.in_features, out_features=4096)\n",
    "train_checkpoint = torch.load(\"./train_checkpoint_{}.pth\".format(4), map_location='cpu')\n",
    "state_dict = train_checkpoint[\"state_dict\"]\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "for k, v in state_dict.items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "net.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preparation...\n"
     ]
    }
   ],
   "source": [
    "batch_size = args.batch_size\n",
    "pdist = nn.PairwiseDistance(p=2)\n",
    "# Data Preparation\n",
    "\n",
    "# note that mean and std is calculated channel-wise\n",
    "# reference: https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457/10\n",
    "print(\"Data Preparation...\")\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.RandomCrop(224, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "img_triplet, label_triplet = pickle.load(open(\"./pickle/train_{}.p\".format(2), 'rb'))\n",
    "train_dataset = utils.TinyImageNet(img_triplet, label_triplet, transform=transform_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, num_workers=2,\n",
    "                                           shuffle=False, sampler=SubsetRandomSampler(range(5000))) \n",
    "# [0, 1,2,3,\n",
    "# 503, 1003, 1503, \n",
    "# 2003, 2004, 2005 ,\n",
    "# 2503, 3003, 3503, 4003, 4503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = utils.generate_testing_data_set()\n",
    "test_dataset = utils.TinyImageNet(img, label, train=False, transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=2,\n",
    "                                              sampler=SubsetRandomSampler([23, 68, 50, 70, 77, 249]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, train_loader, k_closet=30, use_cuda=False):\n",
    "    net.eval()\n",
    "    if args.test_only:\n",
    "        k_closet = 3\n",
    "    f_img_train = []\n",
    "    label_train = []\n",
    "    test_accuracy = []\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        print(\"Calculate Training Feature Embedding...\")\n",
    "        for _, (images, lables) in enumerate(train_loader):\n",
    "            if use_cuda:\n",
    "                q, q_label = images[0].cuda(), lables[0].cuda()\n",
    "            else:\n",
    "                q, q_label = images[0], lables[0]\n",
    "            q = Variable(q)\n",
    "            f_q = net(q)\n",
    "            f_img_train.append(f_q)\n",
    "            label_train.append(q_label)\n",
    "        f_img_train = torch.cat(f_img_train, dim=0)\n",
    "        label_train = torch.cat(label_train, dim=0)\n",
    "        end = time.time()\n",
    "        print(\"Finish in {} min\".format((end-start)/60))\n",
    "        print(\"Testing...\")\n",
    "        for _, (imgs_test, labels_test) in enumerate(test_loader):\n",
    "            if use_cuda:\n",
    "                imgs_test, labels_test = imgs_test.cuda(), labels_test.cuda()\n",
    "            imgs_test = Variable(imgs_test)\n",
    "            f_img_test = net(imgs_test)\n",
    "            for f_img_test_current, label_test_current in zip(f_img_test, labels_test):\n",
    "                f_img_test_current = f_img_test_current.reshape(1, 4096)\n",
    "                f_img_test_current = f_img_test_current.expand(f_img_train.shape[0], 4096)\n",
    "                distance = pdist(f_img_test_current, f_img_train)\n",
    "                predicted = label_train[distance.topk(k_closet, largest=False)[1]]\n",
    "                test_accuracy.append(float(torch.sum(torch.eq(predicted, label_test_current))) / k_closet)\n",
    "        test_accuracy_epoch = np.mean(test_accuracy)\n",
    "\n",
    "        print(\"=> Epoch: [{}/{}] | Testing Accuracy: [{}]\".format(\n",
    "            epoch + 1, args.num_epochs, test_accuracy_epoch))\n",
    "    return test_accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate Training Feature Embedding...\n",
      "Finish in 7.589399047692617 min\n",
      "Testing...\n",
      "=> Epoch: [1/2] | Testing Accuracy: [0.4444444444444444]\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = test(0, train_loader, k_closet=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /Users/ym/.torch/models/resnet50-19c8e357.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet50(pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
