{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "vocab = {'<PAD>': 0, 'is': 1, 'it': 2, 'too': 3, 'late': 4, 'now': 5, 'say': 6, 'sorry': 7, 'ooh': 8, 'yeah': 9} \n",
    "X = [[0, 1, 2, 3, 4, 5, 6], \n",
    "    [7, 7], \n",
    "    [6, 8]]\n",
    "# get the length of each sentence\n",
    "X_lengths = [len(sentence) for sentence in X]\n",
    "# create an empty matrix with padding tokens\n",
    "pad_token = vocab['<PAD>']\n",
    "longest_sent = max(X_lengths)\n",
    "batch_size = len(X)\n",
    "padded_X = np.ones((batch_size, longest_sent)) * pad_token\n",
    "# copy over the actual sequences\n",
    "for i, x_len in enumerate(X_lengths):\n",
    "    sequence = X[i] \n",
    "    padded_X[i, 0:x_len] = sequence[:x_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4., 5., 6.],\n",
       "       [7., 7., 0., 0., 0., 0., 0.],\n",
       "       [6., 8., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = [x+1 for sublist in X for x in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-76fd43cc4960>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "X[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.92s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "coco = COCO('captions_train2014.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = coco.anns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 {'image_id': 318556, 'id': 48, 'caption': 'A very clean and well decorated empty bathroom'}\n"
     ]
    }
   ],
   "source": [
    "for key, item in coco.anns.items():\n",
    "    print (key, item)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_id': 318556,\n",
       " 'id': 48,\n",
       " 'caption': 'A very clean and well decorated empty bathroom'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.anns[48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414113"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_vocab_dict import Vocabulary\n",
    "import pickle\n",
    "with open('./vocab.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.83s)\n",
      "creating index...\n",
      "index created!\n",
      "Tokenization Process: 1.21%.\n",
      "Tokenization Process: 2.41%.\n",
      "Tokenization Process: 3.62%.\n",
      "Tokenization Process: 4.83%.\n",
      "Tokenization Process: 6.04%.\n",
      "Tokenization Process: 7.24%.\n",
      "Tokenization Process: 8.45%.\n",
      "Tokenization Process: 9.66%.\n",
      "Tokenization Process: 10.87%.\n",
      "Tokenization Process: 12.07%.\n",
      "Tokenization Process: 13.28%.\n",
      "Tokenization Process: 14.49%.\n",
      "Tokenization Process: 15.70%.\n",
      "Tokenization Process: 16.90%.\n",
      "Tokenization Process: 18.11%.\n",
      "Tokenization Process: 19.32%.\n",
      "Tokenization Process: 20.53%.\n",
      "Tokenization Process: 21.73%.\n",
      "Tokenization Process: 22.94%.\n",
      "Tokenization Process: 24.15%.\n",
      "Tokenization Process: 25.36%.\n",
      "Tokenization Process: 26.56%.\n",
      "Tokenization Process: 27.77%.\n",
      "Tokenization Process: 28.98%.\n",
      "Tokenization Process: 30.18%.\n",
      "Tokenization Process: 31.39%.\n",
      "Tokenization Process: 32.60%.\n",
      "Tokenization Process: 33.81%.\n",
      "Tokenization Process: 35.01%.\n",
      "Tokenization Process: 36.22%.\n",
      "Tokenization Process: 37.43%.\n",
      "Tokenization Process: 38.64%.\n",
      "Tokenization Process: 39.84%.\n",
      "Tokenization Process: 41.05%.\n",
      "Tokenization Process: 42.26%.\n",
      "Tokenization Process: 43.47%.\n",
      "Tokenization Process: 44.67%.\n",
      "Tokenization Process: 45.88%.\n",
      "Tokenization Process: 47.09%.\n",
      "Tokenization Process: 48.30%.\n",
      "Tokenization Process: 49.50%.\n",
      "Tokenization Process: 50.71%.\n",
      "Tokenization Process: 51.92%.\n",
      "Tokenization Process: 53.13%.\n",
      "Tokenization Process: 54.33%.\n",
      "Tokenization Process: 55.54%.\n",
      "Tokenization Process: 56.75%.\n",
      "Tokenization Process: 57.96%.\n",
      "Tokenization Process: 59.16%.\n",
      "Tokenization Process: 60.37%.\n",
      "Tokenization Process: 61.58%.\n",
      "Tokenization Process: 62.78%.\n",
      "Tokenization Process: 63.99%.\n",
      "Tokenization Process: 65.20%.\n",
      "Tokenization Process: 66.41%.\n",
      "Tokenization Process: 67.61%.\n",
      "Tokenization Process: 68.82%.\n",
      "Tokenization Process: 70.03%.\n",
      "Tokenization Process: 71.24%.\n",
      "Tokenization Process: 72.44%.\n",
      "Tokenization Process: 73.65%.\n",
      "Tokenization Process: 74.86%.\n",
      "Tokenization Process: 76.07%.\n",
      "Tokenization Process: 77.27%.\n",
      "Tokenization Process: 78.48%.\n",
      "Tokenization Process: 79.69%.\n",
      "Tokenization Process: 80.90%.\n",
      "Tokenization Process: 82.10%.\n",
      "Tokenization Process: 83.31%.\n",
      "Tokenization Process: 84.52%.\n",
      "Tokenization Process: 85.73%.\n",
      "Tokenization Process: 86.93%.\n",
      "Tokenization Process: 88.14%.\n",
      "Tokenization Process: 89.35%.\n",
      "Tokenization Process: 90.55%.\n",
      "Tokenization Process: 91.76%.\n",
      "Tokenization Process: 92.97%.\n",
      "Tokenization Process: 94.18%.\n",
      "Tokenization Process: 95.38%.\n",
      "Tokenization Process: 96.59%.\n",
      "Tokenization Process: 97.80%.\n",
      "Tokenization Process: 99.01%.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "from pycocotools.coco import COCO\n",
    "import logging\n",
    "import numpy as np\n",
    "coco = COCO(\"./captions_train2014.json\")\n",
    "ids = coco.anns.keys()\n",
    "counter = Counter()\n",
    "for i, id in enumerate(ids):\n",
    "    caption = str(coco.anns[id]['caption'])\n",
    "    tokens = nltk.tokenize.word_tokenize(caption.lower())\n",
    "    counter.update(tokens)\n",
    "    if (i+1) % 5000 == 0:\n",
    "        print(\"Tokenization Process: {0:.2f}%.\".format((i+1)*100/len(ids)))\n",
    "        #logger.info(\"Tokenization Process: {0:.2f}%.\".format((i+1)*100/len(ids)))\n",
    "# Keep the most frequently appeared words\n",
    "counts = []\n",
    "for _, count in counter.items():\n",
    "    counts.append(count)\n",
    "counts.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25129"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "portion = 0.993\n",
    "cum_ratio = np.cumsum(counts) / np.sum(counts)\n",
    "threshold = min(4,counts[np.argmax(cum_ratio > portion)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for word, count in counter.items():\n",
    "    if count >= threshold:\n",
    "        words.append(word)\n",
    "words.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9952"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from generate_vocab_dict import Vocabulary\n",
    "vocab_path = './vocab.pkl'\n",
    "with open(vocab_path, 'rb') as f:\n",
    "        vocab = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "k = 3; vocab_size=6\n",
    "k_prev_words = torch.LongTensor([[0]] * k)\n",
    "complete_seqs = list()\n",
    "complete_seqs_scores = list()\n",
    "seqs = k_prev_words \n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_scores = torch.zeros(k, 1)\n",
    "top_k_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  image inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 1.],\n",
       "        [1., 2., 3., 4., 5., 1.],\n",
       "        [1., 2., 3., 4., 5., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  repeat k times\n",
    "scores = torch.FloatTensor([[1,2,3,4,5,1], [1,2,3,4,5,1],[1,2,3,4,5,1]])\n",
    "scores = top_k_scores.expand_as(scores) + scores \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5., 4., 3.]), tensor([4, 3, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_scores, top_k_words = scores[0].topk(k, 0, True, True)\n",
    "top_k_scores, top_k_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0]), tensor([4, 3, 2]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_word_inds = top_k_words / vocab_size \n",
    "next_word_inds = top_k_words % vocab_size\n",
    "prev_word_inds, next_word_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4],\n",
       "        [0, 3],\n",
       "        [0, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = torch.cat([seqs[prev_word_inds], next_word_inds.unsqueeze(1)], dim=1)\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2], [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomplete_inds = [ind for ind, next_word in enumerate(next_word_inds) if\n",
    "                           next_word != 5]\n",
    "complete_inds = list(set(range(len(next_word_inds))) - set(incomplete_inds))\n",
    "incomplete_inds,complete_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(complete_inds) > 0:\n",
    "    complete_seqs.extend(seqs[complete_inds].tolist())\n",
    "    complete_seqs_scores.extend(top_k_scores[complete_inds])\n",
    "k -= len(complete_inds)  # reduce beam length accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4],\n",
       "        [0, 3],\n",
       "        [0, 2]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = seqs[incomplete_inds]\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.],\n",
       "         [4.],\n",
       "         [3.]]), tensor([[4],\n",
       "         [3],\n",
       "         [2]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_scores = top_k_scores[incomplete_inds].unsqueeze(1)\n",
    "k_prev_words = next_word_inds[incomplete_inds].unsqueeze(1)\n",
    "\n",
    "top_k_scores, k_prev_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  7., 10.,  9.,  8.,  6.],\n",
       "        [ 5.,  9.,  7.,  8.,  6.,  5.],\n",
       "        [ 4.,  5.,  6.,  8.,  7.,  4.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.FloatTensor([[1,2,5,4,3,1], [1,5,3,4,2,1],[1,2,3,5,4,1]])\n",
    "scores = top_k_scores.expand_as(scores) + scores \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**row: previous**, **column: next**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  9.,  9.]), tensor([2, 3, 7]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_scores, top_k_words = scores.view(-1).topk(k, 0, True, True)\n",
    "top_k_scores, top_k_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 1]), tensor([2, 3, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_word_inds = top_k_words / vocab_size \n",
    "next_word_inds = top_k_words % vocab_size\n",
    "prev_word_inds, next_word_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 1, 2], [])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomplete_inds = [ind for ind, next_word in enumerate(next_word_inds) if\n",
    "                           next_word != 5]\n",
    "complete_inds = list(set(range(len(next_word_inds))) - set(incomplete_inds))\n",
    "incomplete_inds,complete_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(complete_inds) > 0:\n",
    "    complete_seqs.extend(seqs[complete_inds].tolist())\n",
    "    complete_seqs_alpha.extend(seqs_alpha[complete_inds].tolist())\n",
    "    complete_seqs_scores.extend(top_k_scores[complete_inds])\n",
    "k -= len(complete_inds)  # reduce beam length accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4, 2],\n",
       "        [0, 4, 3],\n",
       "        [0, 3, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = torch.cat([seqs[prev_word_inds], next_word_inds.unsqueeze(1)], dim=1)\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[10.],\n",
       "         [ 9.],\n",
       "         [ 9.]]), tensor([[2],\n",
       "         [3],\n",
       "         [1]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_scores = top_k_scores[incomplete_inds].unsqueeze(1)\n",
    "k_prev_words = next_word_inds[incomplete_inds].unsqueeze(1)\n",
    "\n",
    "top_k_scores, k_prev_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meet the `<<end>>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 11.,  12.,  15.,  14.,  13., 110.],\n",
       "        [ 10.,  14.,  12.,  13.,  11.,  10.],\n",
       "        [ 10.,  11.,  12.,  14.,  13.,  10.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = torch.FloatTensor([[1,2,5,4,3,100], [1,5,3,4,2,1],[1,2,3,5,4,1]])\n",
    "scores = top_k_scores.expand_as(scores) + scores \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([110.,  15.,  14.]), tensor([5, 2, 3]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_scores, top_k_words = scores.view(-1).topk(k, 0, True, True)\n",
    "top_k_scores, top_k_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0]), tensor([5, 2, 3]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_word_inds = top_k_words / vocab_size \n",
    "next_word_inds = top_k_words % vocab_size\n",
    "prev_word_inds, next_word_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2], [0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incomplete_inds = [ind for ind, next_word in enumerate(next_word_inds) if\n",
    "                           next_word != 5]\n",
    "complete_inds = list(set(range(len(next_word_inds))) - set(incomplete_inds))\n",
    "incomplete_inds,complete_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(complete_inds) > 0:\n",
    "    complete_seqs.extend(seqs[complete_inds].tolist())\n",
    "    complete_seqs_scores.extend(top_k_scores[complete_inds])\n",
    "k -= len(complete_inds)  # reduce beam length accordingly\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0, 4, 2]], [tensor(110.)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_seqs, complete_seqs_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4, 2, 5],\n",
       "        [0, 4, 2, 2],\n",
       "        [0, 4, 2, 3]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = torch.cat([seqs[prev_word_inds], next_word_inds.unsqueeze(1)], dim=1)\n",
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(img_feature_embedding, decoder_path, beam_size=3, vocab=vocab):\n",
    "    k = beam_size\n",
    "    vocab_size=len(vocab)\n",
    "    decoder = torch.load(decoder_path)\n",
    "    k_prev_words = torch.LongTensor([[vocab.word2idx[\"<<start>>\"]]] * k)\n",
    "    complete_seqs = list()\n",
    "    complete_seqs_scores = list()\n",
    "    seqs = k_prev_words \n",
    "    seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.word2idx[\"<<start>>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5910"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
