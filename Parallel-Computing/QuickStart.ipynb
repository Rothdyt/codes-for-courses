{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fibonacci Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "import logging, threading\n",
    "\n",
    "from queue import Queue\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "# fibo_dict: store each integer (provided as an input) as a key, and its respective key values will be the Fibonacci series values calculated. \n",
    "fibo_dict = {}\n",
    "# shared_queue: the container of our shared data among threads that calculate the Fibonacci series and the thread that inserts elements in the Queue object.\n",
    "shared_queue = Queue()\n",
    "input_list = [3, 10, 5, 7]\n",
    "# queue_condition: synchronize the access to resources according to a speci c condition.\n",
    "queue_condition = threading.Condition()\n",
    "\n",
    "\n",
    "def fibonacci_task(condition):\n",
    "    \"\"\"\n",
    "    The fibonacci_task function receives the condition object as an argument that will \n",
    "    control the fibonacci_task access to `shared_queue`. \n",
    "    \"\"\"\n",
    "    with condition:\n",
    "        while shared_queue.empty(): \n",
    "            logger.info(\"[%s] - waiting for elements in queue...\" % threading.current_thread().name)\n",
    "            condition.wait()\n",
    "        else:\n",
    "            value = shared_queue.get()\n",
    "            a, b = 0, 1\n",
    "            for item in range(value):\n",
    "                a, b = b, a + b\n",
    "                fibo_dict[value] = a\n",
    "            shared_queue.task_done()\n",
    "            logger.debug(\"[%s] fibonacci of key [%d] with result [%d]\" %\n",
    "                (threading.current_thread().name, value, fibo_dict[value]))\n",
    "\n",
    "def queue_task(condition):\n",
    "    \"\"\"\n",
    "    Will be executed by the thread responsible for populating `shared_queue` with elements \n",
    "    to be processed. \n",
    "    \"\"\"\n",
    "    logging.debug('Starting queue_task...')\n",
    "    with condition:\n",
    "        for item in input_list:\n",
    "            shared_queue.put(item)\n",
    "        logging.debug(\"[%s] - Notifying fibonacci_task threads that the queue is ready to consume..\" % threading.current_thread().name)\n",
    "        condition.notifyAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-20 14:16:19,315 - [fibonacci_task_thread1] - waiting for elements in queue...\n",
      "2018-08-20 14:16:19,317 - [fibonacci_task_thread2] - waiting for elements in queue...\n",
      "2018-08-20 14:16:19,320 - [fibonacci_task_thread3] - waiting for elements in queue...\n",
      "2018-08-20 14:16:19,320 - Starting queue_task...\n",
      "2018-08-20 14:16:19,328 - [fibonacci_task_thread4] - waiting for elements in queue...\n",
      "2018-08-20 14:16:19,332 - [queue_task_thread] - Notifying fibonacci_task threads that the queue is ready to consume..\n",
      "2018-08-20 14:16:19,335 - [fibonacci_task_thread1] fibonacci of key [3] with result [2]\n",
      "2018-08-20 14:16:19,342 - [fibonacci_task_thread2] fibonacci of key [10] with result [55]\n",
      "2018-08-20 14:16:19,344 - [fibonacci_task_thread3] fibonacci of key [5] with result [5]\n",
      "2018-08-20 14:16:19,346 - [fibonacci_task_thread4] fibonacci of key [7] with result [13]\n",
      "2018-08-20 14:16:19,349 - [MainThread] - Result: {3: 2, 10: 55, 5: 5, 7: 13}\n"
     ]
    }
   ],
   "source": [
    "fibo_dict = {}\n",
    "shared_queue = Queue()\n",
    "input_list = [3, 10, 5, 7] #simulates user input\n",
    "\n",
    "queue_condition = threading.Condition()\n",
    "\n",
    "\n",
    "threads = [threading.Thread(name='fibonacci_task_thread{}'.format(i+1),\n",
    "            daemon=True, target=fibonacci_task, args=(queue_condition,)) for i in range(4)]\n",
    "\n",
    "[thread.start() for thread in threads]\n",
    "\n",
    "prod = threading.Thread(name='queue_task_thread', daemon=True, target=queue_task, args=(queue_condition,))\n",
    "prod.start()\n",
    "\n",
    "[thread.join() for thread in threads]\n",
    "\n",
    "logger.info(\"[%s] - Result: %s\" % (threading.current_thread().name, fibo_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using multiprocessing.Pipe\n",
    "A pipe consists of a mechanism that establishes communication between two endpoints (two processes in communication). It is a way to create a channel so as to exchange messages among processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value [5] sent by PID [18073]\n",
      "Value [5] received by PID [18072]\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "\n",
    "def producer_task(conn):\n",
    "    value = random.randint(1, 10)\n",
    "    conn.send(value)\n",
    "    print('Value [%d] sent by PID [%d]' % (value, os.getpid()))\n",
    "    conn.close()\n",
    "\n",
    "def consumer_task(conn):\n",
    "    print('Value [%d] received by PID [%d]' % (conn.recv(), os.getpid()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    producer_conn, consumer_conn = Pipe()\n",
    "    consumer = Process(target=consumer_task, args=(consumer_conn,))\n",
    "    producer = Process(target=producer_task, args=(producer_conn,))\n",
    "    \n",
    "    consumer.start()\n",
    "    producer.start()\n",
    "    \n",
    "    consumer.join()\n",
    "    producer.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-21 12:05:10,695 - Producer [Process-5] putting value [15] into queue.. \n",
      "2018-08-21 12:05:10,700 - Producer [Process-5] putting value [15] into queue.. \n",
      "2018-08-21 12:05:10,703 - Producer [Process-5] putting value [4] into queue.. \n",
      "2018-08-21 12:05:10,705 - Producer [Process-5] putting value [16] into queue.. \n",
      "2018-08-21 12:05:10,708 - Producer [Process-5] putting value [17] into queue.. \n",
      "2018-08-21 12:05:10,710 - Producer [Process-5] putting value [1] into queue.. \n",
      "2018-08-21 12:05:10,714 - Producer [Process-5] putting value [11] into queue.. \n",
      "2018-08-21 12:05:10,717 - Producer [Process-5] putting value [1] into queue.. \n",
      "2018-08-21 12:05:10,724 - Producer [Process-5] putting value [14] into queue.. \n",
      "2018-08-21 12:05:10,726 - Producer [Process-5] putting value [17] into queue.. \n",
      "2018-08-21 12:05:10,729 - Producer [Process-5] putting value [7] into queue.. \n",
      "2018-08-21 12:05:10,733 - Producer [Process-5] putting value [6] into queue.. \n",
      "2018-08-21 12:05:10,736 - Producer [Process-5] putting value [4] into queue.. \n",
      "2018-08-21 12:05:10,741 - Producer [Process-5] putting value [18] into queue.. \n",
      "2018-08-21 12:05:10,749 - Producer [Process-5] putting value [15] into queue.. \n",
      "2018-08-21 12:05:10,778 - consumer [Process-6] getting value [15] from queue...\n",
      "2018-08-21 12:05:10,790 - consumer [Process-6] getting value [4] from queue...\n",
      "2018-08-21 12:05:10,810 - consumer [Process-6] getting value [17] from queue...\n",
      "2018-08-21 12:05:10,811 - consumer [Process-8] getting value [16] from queue...\n",
      "2018-08-21 12:05:10,813 - consumer [Process-9] getting value [1] from queue...\n",
      "2018-08-21 12:05:10,822 - consumer [Process-8] getting value [1] from queue...\n",
      "2018-08-21 12:05:10,828 - consumer [Process-6] getting value [11] from queue...\n",
      "2018-08-21 12:05:10,830 - consumer [Process-9] getting value [14] from queue...\n",
      "2018-08-21 12:05:10,833 - consumer [Process-8] getting value [17] from queue...\n",
      "2018-08-21 12:05:10,835 - consumer [Process-8] getting value [4] from queue...\n",
      "2018-08-21 12:05:10,834 - consumer [Process-7] getting value [15] from queue...\n",
      "2018-08-21 12:05:10,838 - consumer [Process-6] getting value [7] from queue...\n",
      "2018-08-21 12:05:10,844 - consumer [Process-8] getting value [18] from queue...\n",
      "2018-08-21 12:05:10,845 - consumer [Process-7] getting value [15] from queue...\n",
      "2018-08-21 12:05:10,849 - consumer [Process-9] getting value [6] from queue...\n",
      "2018-08-21 12:05:10,866 - {15: 610, 4: 3, 16: 987, 17: 1597, 1: 1, 11: 89, 14: 377, 7: 13, 6: 8, 18: 2584}\n"
     ]
    }
   ],
   "source": [
    "#coding: utf-8\n",
    "\n",
    "import sys, logging, time, os, random\n",
    "from multiprocessing import Process, Queue, Pool, \\\n",
    "    cpu_count, current_process, Manager\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "def producer_task(q, fibo_dict):\n",
    "    for i in range(15):\n",
    "        value = random.randint(1, 20)\n",
    "        fibo_dict[value] = None #  fibo_dict: a dictionary generated by a Manager object.\n",
    "        logger.info(\"Producer [%s] putting value [%d] into queue.. \"\n",
    "                % (current_process().name, value))\n",
    "        q.put(value) # q: Queue()\n",
    "\n",
    "def consumer_task(q, fibo_dict):\n",
    "    while not q.empty():\n",
    "        value = q.get(True, 0.05)\n",
    "        a, b = 0, 1\n",
    "        for item in range(value):\n",
    "            a, b = b, a + b\n",
    "            fibo_dict[value] = a\n",
    "        logger.info(\"consumer [%s] getting value [%d] from queue...\"\n",
    "                    % (current_process().name, value))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_queue = Queue()\n",
    "    number_of_cpus = cpu_count()\n",
    "    manager = Manager()\n",
    "    fibo_dict = manager.dict()\n",
    "    \n",
    "    producer = Process(target=producer_task, args=(data_queue, fibo_dict))\n",
    "    producer.start()\n",
    "    producer.join()\n",
    "    \n",
    "    consumer_list = []\n",
    "    for i in range(number_of_cpus):\n",
    "        consumer = Process(target=consumer_task, args=(data_queue, fibo_dict))\n",
    "        consumer.start()\n",
    "        consumer_list.append(consumer)\n",
    "    \n",
    "    [consumer.join() for consumer in consumer_list]\n",
    "    \n",
    "    logger.info(fibo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: utf-8\n",
    "\n",
    "import sys, logging, time, os, random\n",
    "from multiprocessing import Process, Queue, Pool, \\\n",
    "    cpu_count, current_process, Manager\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('%(asctime)s - %(message)s')\n",
    "\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.queues.Queue at 0x10a55dba8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square of [1] is [1]\n",
      "cube of [1] is [1]\n",
      "square of [2] is [4]\n",
      "cube of [2] is [8]\n",
      "square of [3] is [9]\n",
      "cube of [3] is [27]\n",
      "square of [4] is [16]\n",
      "cube of [4] is [64]\n",
      "Tasks done in 20.03281807899475\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Intro to Multiprocessing\n",
    "\"\"\"\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "def cal_square(num_array):\n",
    "    for n in num_array:\n",
    "        print(\"square of [{}] is [{}]\".format(n, n * n))\n",
    "\n",
    "def cal_cube(num_array):\n",
    "    for n in num_array:\n",
    "        print(\"cube of [{}] is [{}]\".format(n, n * n * n))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    num_array = [1, 2, 3, 4]\n",
    "    start = time.time()\n",
    "    process1 = mp.Process(target=cal_square, args=(num_array,))\n",
    "    process2 = mp.Process(target=cal_cube, args=(num_array,))\n",
    "    process1.start()\n",
    "    process2.start()\n",
    "    process1.join()\n",
    "    process2.join()\n",
    "    end = time.time()\n",
    "    print(\"Tasks done in {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Share Global Variables - [shared memory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square of [1] is [1.0]\n",
      "square of [2] is [4.0]\n",
      "square of [3] is [9.0]\n",
      "square of [4] is [16.0]\n",
      "Tasks done in 0.022748947143554688\n",
      "In the main process: [1.0, 4.0, 9.0, 16.0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "multiprocessing.Array & multiprocessing.Value\n",
    "\"\"\"\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "def cal_square(num_array, results_shared_array):\n",
    "    for idx, n in enumerate(num_array):\n",
    "        results_shared_array[idx] = n * n\n",
    "        print(\"square of [{}] is [{}]\".format(n, results_shared_array[idx]))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    num_array = [1, 2, 3, 4]\n",
    "    results_shared_array = mp.Array(\"d\", len(num_array))\n",
    "    start = time.time()\n",
    "    process = mp.Process(target=cal_square, args=(num_array, results_shared_array))\n",
    "    process.start()\n",
    "    process.join()\n",
    "    end = time.time()\n",
    "    print(\"Tasks done in {}\".format(end-start))\n",
    "    print(\"In the main process: {}\".format(results_shared_array[:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "9\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "multiprocessing.Queue\n",
    "\"\"\"\n",
    "\n",
    "import multiprocessing as mp\n",
    "\n",
    "def cal_square(num_array, results_shared_queue):\n",
    "    for n in num_array:\n",
    "        results_shared_queue.put(n * n)\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    num_array = [1, 2, 3, 4]\n",
    "    results_shared_queue = mp.Queue()\n",
    "    start = time.time()\n",
    "    process = mp.Process(target=cal_square, args=(num_array, results_shared_queue))\n",
    "    process.start()\n",
    "    process.join()\n",
    "    end = time.time()\n",
    "    while results_shared_queue.empty() is False:\n",
    "        print(results_shared_queue.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Racing condition\n",
    "\"\"\"\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "\n",
    "def deposit(balance, lock):\n",
    "    for i in range(100):\n",
    "        time.sleep(0.001)\n",
    "        lock.acquire()\n",
    "        balance.value += 1\n",
    "        lock.release()\n",
    "\n",
    "def withdraw(balance, lock):\n",
    "    for i in range(100):\n",
    "        time.sleep(0.002)\n",
    "        lock.acquire()\n",
    "        balance.value -= 1\n",
    "        lock.release()\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    balance = mp.Value(\"i\", 200)\n",
    "    lock = mp.Lock()\n",
    "    process_deposite = mp.Process(target=deposit, args=(balance, lock))\n",
    "    process_witndraw = mp.Process(target=withdraw, args=(balance, lock))\n",
    "    process_deposite.start()\n",
    "    process_witndraw.start()\n",
    "    process_deposite.join()\n",
    "    process_witndraw.join()\n",
    "    print(balance.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapReduce - [Pool]\n",
    "Use Map-Reduce Method to run a function in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool took: [1.6648108959197998] s\n",
      "Serial took: [5.136871099472046] s\n",
      "Difference betwwen two results: 0\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import time\n",
    "import numpy as np\n",
    "def compute(n):\n",
    "    temp = 0\n",
    "    for i in range(n):\n",
    "        temp += i\n",
    "    return temp\n",
    "if __name__ == \"__main__\":\n",
    "    long_list = range(10000)\n",
    "    num_cores = 4\n",
    "    pool_start = time.time()\n",
    "    pool = Pool(processes = num_cores)\n",
    "    pool_result = pool.map(compute, long_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    pool_end = time.time()\n",
    "    print(\"Pool took: [{}] s\".format(pool_end - pool_start))\n",
    "    \n",
    "    serial_start = time.time()\n",
    "    serial_result = []\n",
    "    for e in long_list:\n",
    "        temp = 0\n",
    "        for i in range(e):\n",
    "            temp += i\n",
    "        serial_result.append(temp)\n",
    "    serial_end = time.time()\n",
    "    print(\"Serial took: [{}] s\".format(serial_end - serial_start))\n",
    "    print(\"Difference betwwen two results: {}\".format(np.sum(np.array(pool_result) - np.array(serial_result))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
