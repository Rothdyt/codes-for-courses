{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time \n",
    "import copy\n",
    "from scipy import signal\n",
    "file_name = \"../data/MNISTdata.hdf5\"\n",
    "data = h5py.File(file_name, \"r\")\n",
    "x_train = np.float32(data[\"x_train\"][:]).reshape(-1, 28, 28)\n",
    "y_train = np.int32(np.hstack(np.array(data[\"y_train\"]))).reshape(-1,1)\n",
    "x_test = np.float32(data[\"x_test\"][:]).reshape(-1, 28, 28)\n",
    "y_test = np.int32(np.hstack(np.array(data[\"y_test\"]))).reshape(-1,1)\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    y = copy.deepcopy(x)\n",
    "    y[y<=0] = 0\n",
    "    return y\n",
    "def relu_gradient(x):\n",
    "    y = copy.deepcopy(x)\n",
    "    y[y>=0] = 1\n",
    "    y[y<0] = 0\n",
    "    return y\n",
    "def softmax(U):\n",
    "    temp = np.exp(U)\n",
    "    return temp / np.sum(temp)\n",
    "def convolution_process(img, myfilter):\n",
    "    num_channels= myfilter.shape[0]\n",
    "    ky = myfilter.shape[1]\n",
    "    kx = myfilter.shape[2]\n",
    "    d = img.shape[1]\n",
    "    convoluted = np.zeros((num_channels, d - ky + 1, d - kx + 1))\n",
    "    for filter_idx in range(num_channels):\n",
    "        convoluted[filter_idx, :, :] = signal.correlate2d(img[0,:,:], myfilter[filter_idx, :, :], mode='valid', boundary='wrap')\n",
    "    return convoluted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_initilization(image_size =28, num_channels=1, num_outputs = 10):\n",
    "    d = image_size\n",
    "    params = {}\n",
    "    r = np.random.RandomState(1234)\n",
    "    params[\"K\"] = r.randn(num_channels, 3, 3) / d\n",
    "    ky = params[\"K\"].shape[1]\n",
    "    kx = params[\"K\"].shape[2]\n",
    "    params[\"W\"] = r.randn(num_outputs, \n",
    "                                  d - ky + 1,\n",
    "                                  d - kx + 1) / d\n",
    "    params[\"b\"] = np.zeros((num_outputs, 1))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(img, params):\n",
    "    forward_results = {}\n",
    "    forward_results[\"Z\"] = convolution_process(img, params[\"K\"])\n",
    "    forward_results[\"H\"] = relu(forward_results[\"Z\"])\n",
    "    forward_results[\"U\"] = np.sum(np.multiply(params[\"W\"], \n",
    "                                              forward_results[\"H\"]), axis=(1,2)).reshape(10, 1) + params[\"b\"]\n",
    "    forward_results[\"S\"] = softmax(forward_results[\"U\"])\n",
    "    return forward_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(params, forward_results, img, img_label):\n",
    "    gradients = {}\n",
    "    num_outputs =  forward_results[\"S\"].shape[0]\n",
    "    ey = np.zeros((num_outputs, 1)); ey[img_label] = 1\n",
    "    gradients[\"dU\"] = - (ey - forward_results[\"S\"])\n",
    "    gradients[\"db\"] = gradients[\"dU\"]\n",
    "    gradients[\"delta\"] = np.tensordot(gradients[\"dU\"].squeeze(), params[\"W\"], axes=1)\n",
    "    gradients[\"dW\"] = np.tensordot(gradients[\"dU\"].squeeze(), forward_results[\"H\"][0,:,:], axes=0)\n",
    "    dsigmaZ = relu_gradient(forward_results[\"Z\"])\n",
    "    temp = np.multiply(dsigmaZ, gradients[\"delta\"])\n",
    "    gradients[\"dK\"] = signal.correlate2d(img[0, :,:], temp[0,:,:], mode='valid',  boundary='wrap')\n",
    "    return gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.13017249 -0.1419406  -0.25373653]\n",
      " [-0.38678731 -0.15430067 -0.10469064]\n",
      " [-0.17895828 -0.03021414  0.03015269]]\n"
     ]
    }
   ],
   "source": [
    "img = x_train[0].reshape((1, 28, 28))\n",
    "img_label = y_train[0].reshape((1,1))\n",
    "params = parameter_initilization(image_size =28, num_channels=1, num_outputs = 10)\n",
    "forward_results = forward_prop(img, params)\n",
    "gradients =back_prop(params, forward_results, img, img_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(8).reshape(2,2,2)\n",
    "b = np.arange(4).reshape(1,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [2, 3]],\n",
       "\n",
       "       [[4, 5],\n",
       "        [6, 7]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [2, 3]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
