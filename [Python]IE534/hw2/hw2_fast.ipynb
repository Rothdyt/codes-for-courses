{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few notes on tensor operations in numpy\n",
    "To calculate the \"convolution\" operation defined by the lecture note, which is indeed more often referred as cross-correlation, can be done with the function `signal.correlate2d` in `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27, 37],\n",
       "       [57, 67]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "a = np.arange(9).reshape((3,3))\n",
    "b = np.array([[1,2], [3,4]])\n",
    "signal.correlate2d(a, b, mode='valid', boundary='wrap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $U_k = W_{k,:,:,:} \\cdot H + b_k$ in a more efficient way, where $\\cdot$ is the element-wise-multiplication-and-summation on tensors, we can utilize `numpy.tensordot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[140],\n",
       "       [364],\n",
       "       [588]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.arange(24).reshape((3,2,2,2))\n",
    "H = np.arange(8).reshape((2,2,2))\n",
    "np.tensordot(W, H, axes=3).reshape(3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the $\\delta$, which is a $(d-k_y+1, d - k_x + 1, C)$ tensor in a more efficient way we need use `numpy.squeeze`, `numpy.tensordot`, and the broadcast mechanism. Note the `squeeze` step is a must to avoid dimension issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 64,  70],\n",
       "        [ 76,  82]],\n",
       "\n",
       "       [[ 88,  94],\n",
       "        [100, 106]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dU = np.array([1,2,3])\n",
    "W = np.arange(24).reshape((3,2,2,2))\n",
    "np.tensordot(dU.squeeze(), W, axes=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, for calculating $dW$, we can use code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]]],\n",
       "\n",
       "\n",
       "       [[[ 0,  2],\n",
       "         [ 4,  6]],\n",
       "\n",
       "        [[ 8, 10],\n",
       "         [12, 14]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dU = np.array([1,2])\n",
    "H = np.arange(8).reshape((2,2,2))\n",
    "np.tensordot(dU.squeeze(), H, axes=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time \n",
    "import copy\n",
    "from scipy import signal\n",
    "file_name = \"../data/MNISTdata.hdf5\"\n",
    "data = h5py.File(file_name, \"r\")\n",
    "x_train = np.float32(data[\"x_train\"][:]).reshape(-1, 28, 28)\n",
    "y_train = np.int32(np.hstack(np.array(data[\"y_train\"]))).reshape(-1,1)\n",
    "x_test = np.float32(data[\"x_test\"][:]).reshape(-1, 28, 28)\n",
    "y_test = np.int32(np.hstack(np.array(data[\"y_test\"]))).reshape(-1,1)\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, num_channels=5, learning_rate=0.01, num_epochs=5):\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.num_outputs = 10\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_channels = num_channels\n",
    "        self.d = self.x_train.shape[1]\n",
    "        \n",
    "        self.params = {}\n",
    "        r = np.random.RandomState(1234)\n",
    "        self.params[\"K\"] = r.randn(3, 3, self.num_channels) / self.d\n",
    "        self.ky = self.params[\"K\"].shape[0]\n",
    "        self.kx = self.params[\"K\"].shape[1]\n",
    "        \n",
    "        # channels = 1\n",
    "        self.params[\"W\"] = r.randn(self.num_outputs, \n",
    "                                   self.d - self.ky + 1,\n",
    "                                   self.d - self.kx + 1,\n",
    "                                   self.num_channels) / self.d\n",
    "        self.params[\"b\"] = np.zeros((self.num_outputs, 1))\n",
    "        \n",
    "        self.gradients = {}\n",
    "        \n",
    "        print(\"training sample size: [{}]\\ntest sample size:[{}]\\nchannels:[{}]\".format(self.x_train.shape, self.x_test.shape, self.num_channels))\n",
    "\n",
    "\n",
    "    def convolution_process(self, img):\n",
    "        convoluted = np.zeros((self.d - self.ky + 1, \n",
    "                               self.d - self.kx + 1,\n",
    "                               self.params[\"K\"].shape[2]))\n",
    "        for filter_idx in range(self.params[\"K\"].shape[2]):\n",
    "            convoluted[:, :, filter_idx] = signal.correlate2d(img[0,:,:], self.params[\"K\"][ :, :, filter_idx], mode='valid', boundary='wrap')\n",
    "        return convoluted\n",
    "        \n",
    "    def relu(self, Z):\n",
    "        U = copy.deepcopy(Z)\n",
    "        U[U<=0] = 0\n",
    "        return  U\n",
    "\n",
    "    def relu_gradient(self, Z):\n",
    "        dZ = copy.deepcopy(Z)\n",
    "        dZ[dZ >= 0] = 1\n",
    "        dZ[dZ < 0] = 0\n",
    "        return  dZ\n",
    "\n",
    "    def softmax(self, U):\n",
    "        temp = np.exp(U)\n",
    "        return temp / np.sum(temp)\n",
    "\n",
    "    def forward_propagation(self):\n",
    "        random_index = np.random.randint(self.x_train.shape[0])\n",
    "        self.img = self.x_train[random_index].reshape((1, self.d, self.d))\n",
    "        self.img_label = self.y_train[random_index].reshape((-1,1))\n",
    "        self.forward_results = {}\n",
    "        self.forward_results[\"Z\"] = self.convolution_process(self.img)\n",
    "        self.forward_results[\"H\"] = self.relu(self.forward_results[\"Z\"])\n",
    "        self.forward_results[\"U\"] = np.tensordot(self.params[\"W\"],\n",
    "                                                 self.forward_results[\"H\"], \n",
    "                                                 axes=3).reshape((self.num_outputs ,1)) + self.params[\"b\"]\n",
    "        self.forward_results[\"S\"] = self.softmax(self.forward_results[\"U\"])\n",
    "\n",
    "    def back_propagation(self):\n",
    "        ey = np.zeros((self.num_outputs, 1)); ey[self.img_label] = 1\n",
    "        self.gradients[\"dU\"] = - (ey - self.forward_results[\"S\"])\n",
    "        self.gradients[\"db\"] = self.gradients[\"dU\"]\n",
    "        self.gradients[\"delta\"] = np.tensordot(self.gradients[\"dU\"].squeeze(), self.params[\"W\"], axes=1)\n",
    "        self.gradients[\"dW\"] = np.tensordot(self.gradients[\"dU\"].squeeze(), self.forward_results[\"H\"], axes=0)\n",
    "        dsigmaZ = self.relu_gradient(self.forward_results[\"Z\"])\n",
    "        temp = np.multiply(dsigmaZ, self.gradients[\"delta\"])\n",
    "        self.gradients[\"dK\"] = copy.deepcopy(self.params[\"K\"])\n",
    "        for filter_idx in range(self.params[\"K\"].shape[2]):\n",
    "            self.gradients[\"dK\"][:,:,filter_idx] = signal.correlate2d(self.img[0,:,:], temp[:,:,filter_idx], mode='valid',  boundary='wrap')\n",
    "                                                         \n",
    "    def train(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            if (epoch > 5):\n",
    "                self.learning_rate = 0.001\n",
    "            if (epoch > 10):\n",
    "                self.learning_rate = 0.0001\n",
    "            if (epoch > 15):\n",
    "                self.learning_rate = 0.00001\n",
    "            total_correct = 0\n",
    "            for i in range(int(self.x_train.shape[0])):\n",
    "                self.forward_propagation()\n",
    "                prediction_train =  np.argmax(self.forward_results[\"S\"], axis=0)\n",
    "                total_correct += np.sum(prediction_train == self.img_label)\n",
    "                self.back_propagation()\n",
    "                self.params[\"b\"] -= self.learning_rate * self.gradients[\"db\"]\n",
    "                self.params[\"W\"] -= self.learning_rate * self.gradients[\"dW\"]\n",
    "                self.params[\"K\"] -= self.learning_rate * self.gradients[\"dK\"]\n",
    "            print(\"epoch:{} | Training Accuracy:[{}]\".format(epoch+1, total_correct/(self.x_train.shape[0])))\n",
    "    def test(self):\n",
    "        total_correct_test = 0\n",
    "        for img, img_label in zip(self.x_test, self.y_test):\n",
    "            img = img.reshape((1, self.d, self.d))\n",
    "            img_label = img_label.reshape((-1,1))\n",
    "            Z = self.convolution_process(img)\n",
    "            H = self.relu(Z)\n",
    "            U = np.tensordot(self.params[\"W\"], H, axes=3).reshape((self.num_outputs ,1)) + self.params[\"b\"]\n",
    "            S = self.softmax(U)\n",
    "            prediction_test = np.argmax(S, axis=0)\n",
    "            total_correct_test += np.sum(prediction_test == img_label)\n",
    "        correct_ratio = total_correct_test / self.x_test.shape[0]\n",
    "        return correct_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample size: [(60000, 28, 28)]\n",
      "test sample size:[(10000, 28, 28)]\n",
      "channels:[5]\n"
     ]
    }
   ],
   "source": [
    "myCNN = CNN(x_train, y_train, x_test, y_test,  num_channels=5, learning_rate=0.01, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 | Training Accuracy:[0.93845]\n",
      "epoch:2 | Training Accuracy:[0.9750166666666666]\n",
      "epoch:3 | Training Accuracy:[0.97925]\n",
      "epoch:4 | Training Accuracy:[0.9827833333333333]\n",
      "epoch:5 | Training Accuracy:[0.9856333333333334]\n",
      "epoch:6 | Training Accuracy:[0.9882]\n",
      "epoch:7 | Training Accuracy:[0.9924833333333334]\n",
      "epoch:8 | Training Accuracy:[0.9942333333333333]\n",
      "epoch:9 | Training Accuracy:[0.99505]\n",
      "epoch:10 | Training Accuracy:[0.99485]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "myCNN.train()\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time used for training with 10 epochs is [443.0835828781128] seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Total time used for training with 10 epochs is [{}] seconds\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9796"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myCNN.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "file_name = \"../data/MNISTdata.hdf5\"\n",
    "data = h5py.File(file_name, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KeysView(<HDF5 file \"MNISTdata.hdf5\" (mode r)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
