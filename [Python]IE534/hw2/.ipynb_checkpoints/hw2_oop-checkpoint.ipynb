{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import time \n",
    "import copy\n",
    "from scipy import signal\n",
    "file_name = \"../data/MNISTdata.hdf5\"\n",
    "data = h5py.File(file_name, \"r\")\n",
    "x_train = np.float32(data[\"x_train\"][:]).reshape(-1, 28, 28)\n",
    "y_train = np.int32(np.hstack(np.array(data[\"y_train\"]))).reshape(-1,1)\n",
    "x_test = np.float32(data[\"x_test\"][:]).reshape(-1, 28, 28)\n",
    "y_test = np.int32(np.hstack(np.array(data[\"y_test\"]))).reshape(-1,1)\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN():\n",
    "    def __init__(self, x_train, y_train, x_test, y_test, num_channels=1, learning_rate=0.01, num_epochs=5):\n",
    "        self.x_train = x_train\n",
    "        self.x_test = x_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        self.num_outputs = 10\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_epochs = num_epochs\n",
    "        self.num_channels = num_channels\n",
    "        self.d = self.x_train.shape[1]\n",
    "        \n",
    "        self.params = {}\n",
    "        r = np.random.RandomState(1234)\n",
    "        self.params[\"K\"] = r.randn(self.num_channels, 3, 3) / self.d\n",
    "        self.ky = self.params[\"K\"].shape[1]\n",
    "        self.kx = self.params[\"K\"].shape[2]\n",
    "        \n",
    "        # channels = 1\n",
    "        self.params[\"W\"] = r.randn(self.num_outputs, \n",
    "                                   self.d - self.ky + 1,\n",
    "                                   self.d - self.kx + 1) / self.d\n",
    "        self.params[\"b\"] = np.zeros((self.num_outputs, 1))\n",
    "        \n",
    "        self.gradients = {}\n",
    "        \n",
    "        print(\"training sample size: [{}]\\ntest sample size:[{}]\\nchannels:[{}]\".format(self.x_train.shape, self.x_test.shape, self.num_channels))\n",
    "\n",
    "\n",
    "    def convolution_process(self, img):\n",
    "        convoluted = np.zeros((self.params[\"K\"].shape[0],\n",
    "                               self.d - self.ky + 1, \n",
    "                               self.d - self.kx + 1 ))\n",
    "        for filter_idx in range(self.params[\"K\"].shape[0]):\n",
    "            convoluted[filter_idx, :, :] = signal.correlate2d(img[0,:,:], self.params[\"K\"][filter_idx, :, :], mode='valid', boundary='wrap')\n",
    "        return convoluted\n",
    "        \n",
    "    def relu(self, Z):\n",
    "        U = copy.deepcopy(Z)\n",
    "        U[U<=0] = 0\n",
    "        return  U\n",
    "\n",
    "    def relu_gradient(self, Z):\n",
    "        dZ = copy.deepcopy(Z)\n",
    "        dZ[dZ >= 0] = 1\n",
    "        dZ[dZ < 0] = 0\n",
    "        return  dZ\n",
    "\n",
    "    def softmax(self, U):\n",
    "        temp = np.exp(U)\n",
    "        return temp / np.sum(temp)\n",
    "\n",
    "    def forward_propagation(self):\n",
    "        random_index = np.random.int(self.x_train.shape[0])\n",
    "        self.img = self.x_train[random_index].reshape((1, self.d, self.d))\n",
    "        self.img_label = self.y_train[random_index].reshape((-1,1))\n",
    "        self.forward_results = {}\n",
    "        self.forward_results[\"Z\"] = self.convolution_process(self.img)\n",
    "        self.forward_results[\"H\"] = self.relu(self.forward_results[\"Z\"])\n",
    "        self.forward_results[\"U\"] = np.sum(\n",
    "            np.multiply(params[\"W\"],self.forward_results[\"H\"]), \n",
    "            axis=(1,2)).reshape((self.num_outputs ,1)) + self.params[\"b\"]\n",
    "        self.forward_results[\"S\"] = self.softmax(self.forward_results[\"U\"])\n",
    "#         print(self.forward_results[\"S\"].shape)\n",
    "#         print(np.max(self.forward_results[\"H\"]),  np.max(self.forward_results[\"U\"]), np.max(self.forward_results[\"S\"]))\n",
    "\n",
    "\n",
    "    def back_propagation(self):\n",
    "        ey = np.zeros((self.num_outputs, 1)); ey[self.img_label] = 1\n",
    "        self.gradients[\"dU\"] = - (ey - self.forward_results[\"S\"])\n",
    "        self.gradients[\"db\"] = self.gradients[\"dU\"]\n",
    "        for k in range(self.num_outputs):\n",
    "            self.gradients[\"dW\"][k,:, :] = self.gradients[\"dU\"][k,0] * self.forward_results[\"H\"][0,:,:]\n",
    "            #print(self.forward_results[\"H\"][0,:,:].shape, self.gradients[\"dW\"][k,:, :].shape)\n",
    "        for i in range(self.d - self.ky + 1):\n",
    "            for j in range(self.d - self.kx + 1):\n",
    "                    self.gradients[\"delta\"][i,j] = np.sum(np.multiply(self.gradients[\"dU\"],\n",
    "                                                                      self.params[\"W\"][:,i,j])\n",
    "                                                         )\n",
    "        # to modify in the future\n",
    "        dsigmaZ = self.relu_gradient(self.forward_results[\"Z\"])\n",
    "        #print(dsigmaZ.shape, self.gradients[\"delta\"].shape)\n",
    "        temp = np.multiply(dsigmaZ, self.gradients[\"delta\"])\n",
    "        #self.gradients[\"dK\"] = self.convolution(self.img[0, :,:], temp[0,:,:])\n",
    "        self.gradients[\"dK\"] = signal.correlate2d(self.img[0, :,:], temp[0,:,:], mode='valid',  boundary='wrap')\n",
    "        #print(self.gradients[\"dK\"].shape)\n",
    "                                                         \n",
    "    def train(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            if (epoch > 5):\n",
    "                self.learning_rate = 0.001\n",
    "            if (epoch > 10):\n",
    "                self.learning_rate = 0.0001\n",
    "            if (epoch > 15):\n",
    "                self.learning_rate = 0.00001\n",
    "            total_correct = 0\n",
    "            for i in range(int(self.x_train.shape[0])):\n",
    "                if i %1000 == 0:\n",
    "                    print(i)\n",
    "                self.forward_propagation()\n",
    "                prediction_train =  np.argmax(self.forward_results[\"S\"], axis=0)\n",
    "                total_correct += np.sum(prediction_train == self.img_label)\n",
    "                self.back_propagation()\n",
    "                self.params[\"b\"] -= self.learning_rate * self.gradients[\"db\"]\n",
    "                for k in range(self.num_outputs):\n",
    "                    self.params[\"W\"][k, : , :] -= self.learning_rate * self.gradients[\"dW\"][k, :, :]\n",
    "                self.params[\"K\"] -= self.learning_rate * self.gradients[\"dK\"]\n",
    "            print(\"epoch:{} | Training Accuracy:[{}]\".format(epoch+1, total_correct/(self.x_train.shape[0])))\n",
    "#     def test(self):\n",
    "        \n",
    "#         self.Z = self.convolution_process(self.img)\n",
    "#         self.forward_results[\"H\"] = self.relu(self.forward_results[\"Z\"])\n",
    "#         self.forward_results[\"U\"] = np.zeros((self.num_channels,self.num_outputs, 1))\n",
    "#         for i in range(self.num_outputs):\n",
    "#             # to modify in the future\n",
    "#             self.forward_results[\"U\"][1,i,1] = np.tensordot(self.params[\"W\"][i, :, :],\n",
    "#                                                           self.forward_results[\"H\"],\n",
    "#                                                           axes=((0,1),(0,1))\n",
    "#                                                          ) + self.params[\"b\"][i,1]\n",
    "#         # to modify in the future\n",
    "#         self.forward_results[\"S\"] = self.softmax(self.forward_results[\"U\"][1,:,:])\n",
    "\n",
    "\n",
    "#         self.prediction = np.apply_along_axis(np.argmax, 0, self.S)\n",
    "#         correct_ratio = np.mean(self.prediction == self.y_test)\n",
    "#         return correct_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training sample size: [(60000, 28, 28)]\n",
      "test sample size:[(10000, 28, 28)]\n",
      "channels:[1]\n"
     ]
    }
   ],
   "source": [
    "myCNN = CNN(x_train, y_train, x_test, y_test,  num_channels=1, learning_rate=0.01, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(10, 1)\n",
      "0.10559196 0.029631028993130838 0.10325213706442467\n",
      "(10, 1)\n",
      "0.15898757 0.022859154841332184 0.10448223375865345\n",
      "(10, 1)\n",
      "0.18794324 0.07975934837331404 0.10737854767855334\n",
      "(10, 1)\n",
      "0.1638569 0.04160604349259608 0.10511905197422843\n",
      "(10, 1)\n",
      "0.1579435 0.025309560262508007 0.10353314398273944\n",
      "(10, 1)\n",
      "0.163319 0.026652705004170187 0.1037957901392676\n",
      "(10, 1)\n",
      "0.19601814 0.0382203001910378 0.10524229255215062\n",
      "(10, 1)\n",
      "0.15340677 0.011113168636892549 0.1029144676422101\n",
      "(10, 1)\n",
      "0.22195645 0.013835289723971887 0.10338718860326214\n",
      "(10, 1)\n",
      "0.22544959 0.13281283230998736 0.1169149885226352\n",
      "(10, 1)\n",
      "0.25984836 0.01572737649475428 0.10595447837803901\n",
      "(10, 1)\n",
      "0.32038295 0.05772365898331266 0.11158202588103501\n",
      "(10, 1)\n",
      "0.41474807 0.13048300342097932 0.11774827655528608\n",
      "(10, 1)\n",
      "0.48750994 0.07431967538455306 0.11885742240827671\n",
      "(10, 1)\n",
      "0.54190874 0.06234354407330665 0.11453599558701351\n",
      "(10, 1)\n",
      "0.7312042 0.22388202657622497 0.13778695979182912\n",
      "(10, 1)\n",
      "0.8530732 0.5122127800642706 0.17851650241349803\n",
      "(10, 1)\n",
      "0.96613866 0.21854428359683437 0.14103949465924642\n",
      "(10, 1)\n",
      "1.0808656 0.002361296335075643 0.13568813045242706\n",
      "(10, 1)\n",
      "1.3841786 -0.0025554013756272226 0.17160799967260268\n",
      "(10, 1)\n",
      "1.7025025 -0.10416999805921953 0.15812436166307145\n",
      "(10, 1)\n",
      "1.9324156 -0.23807509617017844 0.16746545193554166\n",
      "(10, 1)\n",
      "2.289322 -0.45164412110643404 0.18031415960182504\n",
      "(10, 1)\n",
      "2.7937467 -1.3657842560298172 0.1841605472663271\n",
      "(10, 1)\n",
      "2.869425 -0.4832320215026974 0.19404350166332018\n",
      "(10, 1)\n",
      "3.5783424 -2.202297027133101 0.14907867877905406\n",
      "(10, 1)\n",
      "4.215976 -1.980331608896412 0.44159888119366825\n",
      "(10, 1)\n",
      "4.1012616 -1.6523389305340948 0.3067491602370332\n",
      "(10, 1)\n",
      "5.318155 -4.894504123900387 0.19597636614720493\n",
      "(10, 1)\n",
      "5.612458 -7.233643033050218 0.17441845187146937\n",
      "(10, 1)\n",
      "7.656611 -8.132892499669135 0.5346924225548969\n",
      "(10, 1)\n",
      "5.793173 -4.998411356536065 0.3831583425320812\n",
      "(10, 1)\n",
      "9.5873575 -12.258112962507225 0.6723718850120494\n",
      "(10, 1)\n",
      "10.435762 -12.15734561985248 0.7398924843741527\n",
      "(10, 1)\n",
      "13.008857 -30.421119483314495 0.4829455246891381\n",
      "(10, 1)\n",
      "15.269653 -32.125232716140516 0.8792125838732946\n",
      "(10, 1)\n",
      "18.895346 -48.6201989385029 0.9594922306847117\n",
      "(10, 1)\n",
      "22.605024 -89.01130017627827 0.9979718477597171\n",
      "(10, 1)\n",
      "24.86414 -64.6491635550662 0.9999585575966911\n",
      "(10, 1)\n",
      "29.854942 -60.30816269045454 0.744078578914742\n",
      "(10, 1)\n",
      "34.15612 -99.61289556917949 0.9701605009152389\n",
      "(10, 1)\n",
      "35.334694 -87.79576783824656 0.9710680102239161\n",
      "(10, 1)\n",
      "45.764454 -132.7632869505326 0.8135330140154766\n",
      "(10, 1)\n",
      "49.890984 -182.0881455809382 1.0\n",
      "(10, 1)\n",
      "58.38746 -474.88185199605874 0.9998799188230096\n",
      "(10, 1)\n",
      "70.78076 -418.22980145009524 1.0\n",
      "(10, 1)\n",
      "80.92342 -670.7054761630765 1.0\n",
      "(10, 1)\n",
      "51.947342 -276.944738417601 1.0\n",
      "(10, 1)\n",
      "74.59508 -682.3255803507193 1.0\n",
      "(10, 1)\n",
      "115.981094 -1124.4221517576368 nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ym/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:71: RuntimeWarning: invalid value encountered in true_divide\n",
      "/Users/ym/anaconda/lib/python3.6/site-packages/numpy/core/_methods.py:26: RuntimeWarning: invalid value encountered in reduce\n",
      "  return umr_maximum(a, axis, None, out, keepdims)\n",
      "/Users/ym/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:56: RuntimeWarning: invalid value encountered in less_equal\n",
      "/Users/ym/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:65: RuntimeWarning: invalid value encountered in greater\n",
      "/Users/ym/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:66: RuntimeWarning: invalid value encountered in less\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n",
      "(10, 1)\n",
      "nan nan nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2ba23c1fb9c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyCNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-c28252291315>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mprediction_train\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"S\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0mtotal_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mback_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"db\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c28252291315>\u001b[0m in \u001b[0;36mback_propagation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     self.gradients[\"delta\"][i,j] = np.sum(np.multiply(self.gradients[\"dU\"],\n\u001b[0;32m--> 109\u001b[0;31m                                                                       self.params[\"W\"][:,i,j])\n\u001b[0m\u001b[1;32m    110\u001b[0m                                                          )\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# to modify in the future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "myCNN.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(img, myfilter):\n",
    "    ky, kx = myfilter.shape\n",
    "    d = img.shape[1]\n",
    "    Z = np.zeros((d - ky + 1, d - kx + 1))\n",
    "    for i in range(Z.shape[0]):\n",
    "        for j in range(Z.shape[1]):\n",
    "            Z[i,j] = np.tensordot(img[0, i:(i+ky), j:(j+kx)], myfilter, axes=((0,1),(0,1)))\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21., 27.],\n",
       "       [39., 45.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.array([[1,2,3], [4,5,6], [7,8,9]]).reshape((1,3,3))\n",
    "myfilter = np.array([[1,1], [2,2]])\n",
    "convolution(img, myfilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = np.array([[1,2,3], [4,5,6]]).reshape((1,2,3))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 27],\n",
       "       [39, 45]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signal.correlate2d(img[0,:,:], myfilter, mode='valid',  boundary='wrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.,  0.],\n",
       "        [ 3.,  4.],\n",
       "        [ 5., -6.]],\n",
       "\n",
       "       [[ 7.,  8.],\n",
       "        [-9.,  2.],\n",
       "        [-5.,  9.]]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.float32(np.array([[-1,0,3], [4,5,-6], [7,8,-9], [2, -5,9]]).reshape((2,3,2)))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a == 0] = 1e-8\n",
    "a[a >=0] = 1\n",
    "a[a< 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.]],\n",
       "\n",
       "       [[1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0.],\n",
       "        [3., 4.],\n",
       "        [5., 0.]],\n",
       "\n",
       "       [[7., 8.],\n",
       "        [0., 2.],\n",
       "        [0., 9.]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Z: must be of size (num_channels, d - ky + 1, d - kx + 1)\n",
    "    \"\"\"\n",
    "    U = copy.deepcopy(Z)\n",
    "    U[U<=0] = 0\n",
    "    return  U\n",
    "relu(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
